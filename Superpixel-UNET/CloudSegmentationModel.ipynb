{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Utilities/')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import importlib\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "\n",
    "## Import MDS from sklearn\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "mds = MDS(n_components=1, random_state=0, normalized_stress='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet1D(\n",
      "  (encoder): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv1d(6, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): ConvTranspose1d(512, 256, kernel_size=(2,), stride=(2,))\n",
      "      (1): Conv1d(512, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): ModuleList(\n",
      "      (0): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,))\n",
      "      (1): Conv1d(256, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): ModuleList(\n",
      "      (0): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,))\n",
      "      (1): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (3): ModuleList(\n",
      "      (0): ConvTranspose1d(64, 32, kernel_size=(2,), stride=(2,))\n",
      "      (1): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (logits): Conv1d(32, 2, kernel_size=(1,), stride=(1,))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class UNet1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, depth=2, num_layers=2):\n",
    "        super(UNet1D, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.depth = depth\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.num_start_filters = 32\n",
    "\n",
    "        self._create_unet(self.in_channels, self.num_start_filters)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv1d(self.num_start_filters * 2 ** (self.depth - 1), 2 * self.num_start_filters * 2 ** (self.depth - 1), kernel_size=1, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.logits = nn.Conv1d(self.num_start_filters, self.out_channels, 1, 1)\n",
    "\n",
    "\n",
    "    def _create_encoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _create_decoder_block(self, in_channels, out_channels):\n",
    "        return nn.ModuleList([nn.ConvTranspose1d(in_channels, in_channels//2, kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2),\n",
    "            nn.ReLU()])\n",
    "\n",
    "    def _create_unet(self, in_channels, out_channels):\n",
    "        for _ in range(self.depth):\n",
    "            self.encoder.append(self._create_encoder_block(in_channels, out_channels))\n",
    "            in_channels, out_channels = out_channels, out_channels*2\n",
    "\n",
    "        out_channels = in_channels\n",
    "        in_channels = in_channels * 2\n",
    "        for _ in range(self.depth):\n",
    "            self.decoder.append(self._create_decoder_block(in_channels, out_channels))\n",
    "            in_channels, out_channels = out_channels, out_channels//2\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = []\n",
    "        for enc in self.encoder:\n",
    "            x = enc(x)\n",
    "            encoded.append(x)\n",
    "            x = nn.MaxPool1d(kernel_size=2, stride=2)(x)\n",
    "\n",
    "        x = self.bottleneck(x)  # Bottleneck layer\n",
    "\n",
    "        for dec in self.decoder:\n",
    "            ## Adding input with encoder concatenation\n",
    "            enc_output = encoded.pop()\n",
    "            x = dec[0](x)\n",
    "            ## Pad the decoder output to match the encoder output\n",
    "            diff = enc_output.shape[2] - x.shape[2]\n",
    "            x = F.pad(x, (diff // 2, diff - diff // 2))\n",
    "            x = torch.cat((enc_output, x), dim=1)\n",
    "            x = dec[1](x)\n",
    "            x = dec[2](x)\n",
    "        ## Add softmax to logits\n",
    "        # x = self.softmax(x)\n",
    "\n",
    "        return self.logits(x)\n",
    "\n",
    "input_channels = 6 \n",
    "output_channels = 2\n",
    "depth = 4\n",
    "num_layers = 2\n",
    "\n",
    "model = UNet1D(input_channels, output_channels, depth, num_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6, 300])\n",
      "Output shape: torch.Size([1, 2, 300])\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "num_superpixels = 300\n",
    "num_features = 6\n",
    "synthetic_data = np.random.rand(num_superpixels, num_features)\n",
    "synthetic_data = torch.tensor(synthetic_data, dtype=torch.float32)\n",
    "\n",
    "#Reshape\n",
    "synthetic_data = synthetic_data.unsqueeze(0).transpose(1, 2)\n",
    "\n",
    "# Pass the synthetic data through the U-Net model\n",
    "with torch.no_grad():\n",
    "    output = model(synthetic_data)\n",
    "\n",
    "print(\"Input shape:\", synthetic_data.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LightningModule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        # BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = dice_loss\n",
    "        \n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudSegmentationModel(pl.LightningModule):\n",
    "    def __init__(self, depth=3):\n",
    "        super(CloudSegmentationModel, self).__init__()\n",
    "        self.unet = UNet1D(in_channels=6, out_channels=1, depth=depth)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return nn.Sigmoid()(self.unet(x))\n",
    "\n",
    "    def accuracy_score(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().detach().numpy()\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "        y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        superpixel, label = batch\n",
    "        output = self(superpixel)\n",
    "        loss = nn.BCELoss()(output, label)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted = torch.round(output)\n",
    "        correct = (predicted == label).sum().item()\n",
    "        total = label.size(0) * label.size(1) * label.size(2)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_accuracy', accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        superpixel, label = batch\n",
    "        output = self(superpixel)\n",
    "        loss = nn.BCELoss()(output, label)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted = torch.round(output)\n",
    "        correct = (predicted == label).sum().item()\n",
    "        total = label.size(0) * label.size(1) * label.size(2)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_accuracy', accuracy, on_step=False, on_epoch=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:  386945\n",
      "Input shape: torch.Size([1, 6, 300])\n",
      "Output shape: torch.Size([1, 1, 300])\n"
     ]
    }
   ],
   "source": [
    "model = CloudSegmentationModel()\n",
    "print(\"Parameters: \",count_parameters(model))\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(synthetic_data)\n",
    "\n",
    "print(\"Input shape:\", synthetic_data.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GP65\\anaconda3\\lib\\site-packages\\rasterio\\__init__.py:333: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "patches,mask = data_utils.get_patch(path_to_folders_images = \"../Dataset/Natural_False_Color/\", path_to_folders_labels = \"../Dataset/Entire_scene_gts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38eb9115b2e245d4b85e52ec3fd2e3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1472 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i,j in tqdm(list(zip(patches,mask))):\n",
    "    try:\n",
    "        output = data_utils.convert_image_array_to_slic_with_properties(i,j,n_segments=300) \n",
    "\n",
    "        ## Getting the X and y arrays\n",
    "        X_array = np.array([list(list(i.values())[0]) + list(i.values())[1:] for i in output[1]])\n",
    "        y_array = np.array(output[2])\n",
    "\n",
    "        ## Normalizing the X_array columwise\n",
    "        X_array[:,0] = X_array[:,0]/255\n",
    "        X_array[:,1] = X_array[:,1]/255\n",
    "        X_array[:,2] = X_array[:,2]/255\n",
    "        X_array[:,3] = X_array[:,3]/512\n",
    "        X_array[:,4] = X_array[:,4]/512\n",
    "        X_array[:,5] = X_array[:,5]/1000\n",
    "\n",
    "\n",
    "\n",
    "        ## Pad the X_array with -1 and y_array with 0 upto 300\n",
    "        X_array = np.pad(X_array,((0,300-X_array.shape[0]),(0,0)),mode='constant',constant_values=-1)\n",
    "        y_array = np.pad(y_array,(0,300-y_array.shape[0]),mode='constant',constant_values=0)\n",
    "\n",
    "        ## Ordering\n",
    "        ordering = mds.fit_transform(X_array[:,3:5]).reshape(-1)\n",
    "        X_array = X_array[ordering.argsort()]\n",
    "        y_array = y_array[ordering.argsort()].reshape(-1,1)\n",
    "\n",
    "        ## Appending\n",
    "        X.append(X_array)\n",
    "        y.append(y_array)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../Dataset/X.npy', np.array(X))\n",
    "# np.save('../Dataset/Y.npy', np.array(y))\n",
    "\n",
    "X = np.load('../Dataset/X.npy')\n",
    "y = np.load('../Dataset/Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_item = torch.tensor(self.X[idx], dtype=torch.float32).T\n",
    "        y_item = torch.tensor(self.y[idx], dtype=torch.float32).T\n",
    "        return x_item, y_item\n",
    "\n",
    "def create_dataloader(X, y, batch_size=32, shuffle=True):\n",
    "    dataset = CustomDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide X and Y into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader(X_train,y_train,batch_size=64,shuffle=True)\n",
    "test_loader = create_dataloader(X_test,y_test,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and trainer\n",
    "segmentationModel = CloudSegmentationModel(depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger('lightning_logs/', name='sgd_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath = './/model_checkpt/',\n",
    "    filename = 'best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    verbose = True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | unet | UNet1D | 386 K \n",
      "--------------------------------\n",
      "386 K     Trainable params\n",
      "0         Non-trainable params\n",
      "386 K     Total params\n",
      "1.548     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 34/34 [00:00<00:00, 34.01it/s, loss=0.618, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 27: 'val_loss' reached 0.58780 (best 0.58780), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 34/34 [00:00<00:00, 46.01it/s, loss=0.514, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 54: 'val_loss' reached 0.51053 (best 0.51053), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 34/34 [00:00<00:00, 41.64it/s, loss=0.49, v_num=4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 81: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 34/34 [00:00<00:00, 49.78it/s, loss=0.483, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 108: 'val_loss' reached 0.48426 (best 0.48426), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.466, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 135: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 34/34 [00:00<00:00, 49.10it/s, loss=0.468, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 162: 'val_loss' reached 0.48265 (best 0.48265), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 34/34 [00:00<00:00, 49.57it/s, loss=0.452, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 189: 'val_loss' reached 0.46208 (best 0.46208), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 34/34 [00:00<00:00, 49.06it/s, loss=0.426, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 216: 'val_loss' reached 0.42145 (best 0.42145), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 34/34 [00:00<00:00, 50.41it/s, loss=0.392, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 243: 'val_loss' reached 0.37788 (best 0.37788), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 34/34 [00:00<00:00, 51.13it/s, loss=0.374, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 270: 'val_loss' reached 0.37673 (best 0.37673), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.359, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 297: 'val_loss' reached 0.36042 (best 0.36042), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 34/34 [00:00<00:00, 50.03it/s, loss=0.353, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 324: 'val_loss' reached 0.35486 (best 0.35486), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 34/34 [00:00<00:00, 50.44it/s, loss=0.351, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 351: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 34/34 [00:00<00:00, 48.74it/s, loss=0.357, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 378: 'val_loss' reached 0.35386 (best 0.35386), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 34/34 [00:00<00:00, 50.28it/s, loss=0.343, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 405: 'val_loss' reached 0.35183 (best 0.35183), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 34/34 [00:00<00:00, 49.28it/s, loss=0.335, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 432: 'val_loss' reached 0.34039 (best 0.34039), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.354, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 459: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.343, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 486: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 34/34 [00:00<00:00, 49.35it/s, loss=0.349, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 513: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 34/34 [00:00<00:00, 48.98it/s, loss=0.334, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 540: 'val_loss' reached 0.33909 (best 0.33909), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.334, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 567: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.334, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 594: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 34/34 [00:00<00:00, 48.50it/s, loss=0.326, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 621: 'val_loss' reached 0.33821 (best 0.33821), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 34/34 [00:00<00:00, 49.74it/s, loss=0.334, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 648: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 34/34 [00:00<00:00, 50.75it/s, loss=0.33, v_num=4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 675: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 34/34 [00:00<00:00, 49.67it/s, loss=0.328, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 702: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 34/34 [00:00<00:00, 49.97it/s, loss=0.333, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 729: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.33, v_num=4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 756: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 34/34 [00:00<00:00, 47.45it/s, loss=0.324, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 783: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 34/34 [00:00<00:00, 50.24it/s, loss=0.334, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 810: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 34/34 [00:00<00:00, 48.36it/s, loss=0.329, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 837: 'val_loss' reached 0.33400 (best 0.33400), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 34/34 [00:00<00:00, 50.95it/s, loss=0.318, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 864: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 34/34 [00:00<00:00, 50.45it/s, loss=0.325, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 891: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.328, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 918: 'val_loss' reached 0.33119 (best 0.33119), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 34/34 [00:00<00:00, 49.83it/s, loss=0.319, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 945: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 34/34 [00:00<00:00, 49.17it/s, loss=0.325, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, global step 972: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 34/34 [00:00<00:00, 50.26it/s, loss=0.321, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, global step 999: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 34/34 [00:00<00:00, 49.38it/s, loss=0.328, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 1026: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 34/34 [00:00<00:00, 48.67it/s, loss=0.326, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, global step 1053: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 34/34 [00:00<00:00, 50.37it/s, loss=0.318, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 1080: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.33, v_num=4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 1107: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 34/34 [00:00<00:00, 49.42it/s, loss=0.32, v_num=4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, global step 1134: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 34/34 [00:00<00:00, 49.68it/s, loss=0.32, v_num=4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 1161: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 34/34 [00:00<00:00, 49.45it/s, loss=0.316, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 1188: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 34/34 [00:00<00:00, 46.64it/s, loss=0.315, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, global step 1215: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 34/34 [00:00<00:00, 49.34it/s, loss=0.313, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, global step 1242: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 34/34 [00:00<00:00, 47.44it/s, loss=0.312, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46, global step 1269: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 34/34 [00:00<00:00, 44.87it/s, loss=0.313, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, global step 1296: 'val_loss' reached 0.33109 (best 0.33109), saving model to 'D:\\\\Projects\\\\ComputerVision_CloudSegmentation\\\\Superpixel-UNET\\\\model_checkpt\\\\best-checkpoint-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 34/34 [00:00<00:00, 50.17it/s, loss=0.323, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, global step 1323: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.322, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 1350: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.324, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50, global step 1377: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 34/34 [00:00<00:00, 49.38it/s, loss=0.31, v_num=4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51, global step 1404: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 34/34 [00:00<00:00, 50.00it/s, loss=0.319, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52, global step 1431: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 34/34 [00:00<00:00, 49.60it/s, loss=0.317, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53, global step 1458: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 34/34 [00:00<00:00, 46.75it/s, loss=0.319, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54, global step 1485: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 34/34 [00:00<00:00, 48.88it/s, loss=0.312, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55, global step 1512: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 34/34 [00:00<00:00, 50.22it/s, loss=0.315, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56, global step 1539: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.311, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57, global step 1566: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 34/34 [00:00<00:00, 50.21it/s, loss=0.315, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58, global step 1593: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 34/34 [00:00<00:00, 50.56it/s, loss=0.308, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 1620: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 34/34 [00:00<00:00, 50.59it/s, loss=0.309, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60, global step 1647: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.308, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61, global step 1674: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 34/34 [00:00<00:00, 50.44it/s, loss=0.307, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62, global step 1701: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 34/34 [00:00<00:00, 49.28it/s, loss=0.315, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63, global step 1728: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.318, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64, global step 1755: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 34/34 [00:00<00:00, 51.13it/s, loss=0.313, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65, global step 1782: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 34/34 [00:00<00:00, 50.15it/s, loss=0.309, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66, global step 1809: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.308, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67, global step 1836: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 34/34 [00:00<00:00, 46.64it/s, loss=0.308, v_num=4]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger = logger,\n",
    "    gpus=1 if torch.cuda.is_available() else None,\n",
    "    max_epochs=100,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=20), checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Train the model using the trainer\n",
    "trainer.fit(segmentationModel, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a995742e464990b4cd8c54d4865983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6364, Accuracy: 0.6186\n",
      "Test Loss: 0.5749, Accuracy: 0.6813\n",
      "Epoch [2/100], Loss: 0.5424, Accuracy: 0.8075\n",
      "Test Loss: 0.5319, Accuracy: 0.7332\n",
      "Epoch [3/100], Loss: 0.5089, Accuracy: 0.7436\n",
      "Test Loss: 0.5077, Accuracy: 0.7726\n",
      "Epoch [4/100], Loss: 0.4980, Accuracy: 0.7191\n",
      "Test Loss: 0.5190, Accuracy: 0.7041\n",
      "Epoch [5/100], Loss: 0.4874, Accuracy: 0.7807\n",
      "Test Loss: 0.5052, Accuracy: 0.7741\n",
      "Epoch [6/100], Loss: 0.4865, Accuracy: 0.8059\n",
      "Test Loss: 0.4932, Accuracy: 0.7659\n",
      "Epoch [7/100], Loss: 0.4706, Accuracy: 0.7999\n",
      "Test Loss: 0.4940, Accuracy: 0.6825\n",
      "Epoch [8/100], Loss: 0.4623, Accuracy: 0.7862\n",
      "Test Loss: 0.4570, Accuracy: 0.7324\n",
      "Epoch [9/100], Loss: 0.4311, Accuracy: 0.7923\n",
      "Test Loss: 0.4193, Accuracy: 0.8353\n",
      "Epoch [10/100], Loss: 0.4135, Accuracy: 0.8057\n",
      "Test Loss: 0.4009, Accuracy: 0.8276\n",
      "Epoch [11/100], Loss: 0.3908, Accuracy: 0.8448\n",
      "Test Loss: 0.3932, Accuracy: 0.8185\n",
      "Epoch [12/100], Loss: 0.3822, Accuracy: 0.8141\n",
      "Test Loss: 0.4353, Accuracy: 0.8000\n",
      "Epoch [13/100], Loss: 0.3903, Accuracy: 0.8330\n",
      "Test Loss: 0.4030, Accuracy: 0.7826\n",
      "Epoch [14/100], Loss: 0.3776, Accuracy: 0.8352\n",
      "Test Loss: 0.3858, Accuracy: 0.8310\n",
      "Epoch [15/100], Loss: 0.3726, Accuracy: 0.8716\n",
      "Test Loss: 0.4051, Accuracy: 0.8147\n",
      "Epoch [16/100], Loss: 0.3773, Accuracy: 0.8135\n",
      "Test Loss: 0.3749, Accuracy: 0.8522\n",
      "Epoch [17/100], Loss: 0.3691, Accuracy: 0.8159\n",
      "Test Loss: 0.3772, Accuracy: 0.8331\n",
      "Epoch [18/100], Loss: 0.3716, Accuracy: 0.8617\n",
      "Test Loss: 0.3750, Accuracy: 0.8180\n",
      "Epoch [19/100], Loss: 0.3648, Accuracy: 0.8038\n",
      "Test Loss: 0.3731, Accuracy: 0.8432\n",
      "Epoch [20/100], Loss: 0.3680, Accuracy: 0.8122\n",
      "Test Loss: 0.3747, Accuracy: 0.8600\n",
      "Epoch [21/100], Loss: 0.3588, Accuracy: 0.8341\n",
      "Test Loss: 0.3594, Accuracy: 0.8796\n",
      "Epoch [22/100], Loss: 0.3608, Accuracy: 0.7990\n",
      "Test Loss: 0.3704, Accuracy: 0.8431\n",
      "Epoch [23/100], Loss: 0.3631, Accuracy: 0.8094\n",
      "Test Loss: 0.3960, Accuracy: 0.8056\n",
      "Epoch [24/100], Loss: 0.3776, Accuracy: 0.7797\n",
      "Test Loss: 0.3749, Accuracy: 0.8666\n",
      "Epoch [25/100], Loss: 0.3576, Accuracy: 0.8825\n",
      "Test Loss: 0.3614, Accuracy: 0.8769\n",
      "Epoch [26/100], Loss: 0.3510, Accuracy: 0.8488\n",
      "Test Loss: 0.3588, Accuracy: 0.8504\n",
      "Epoch [27/100], Loss: 0.3499, Accuracy: 0.8520\n",
      "Test Loss: 0.3615, Accuracy: 0.8409\n",
      "Epoch [28/100], Loss: 0.3496, Accuracy: 0.8516\n",
      "Test Loss: 0.3797, Accuracy: 0.8279\n",
      "Epoch [29/100], Loss: 0.3544, Accuracy: 0.8322\n",
      "Test Loss: 0.3603, Accuracy: 0.8097\n",
      "Epoch [30/100], Loss: 0.3473, Accuracy: 0.8646\n",
      "Test Loss: 0.3570, Accuracy: 0.8493\n",
      "Epoch [31/100], Loss: 0.3488, Accuracy: 0.9014\n",
      "Test Loss: 0.3550, Accuracy: 0.8499\n",
      "Epoch [32/100], Loss: 0.3517, Accuracy: 0.8516\n",
      "Test Loss: 0.3578, Accuracy: 0.8639\n",
      "Epoch [33/100], Loss: 0.3530, Accuracy: 0.8925\n",
      "Test Loss: 0.3826, Accuracy: 0.8382\n",
      "Epoch [34/100], Loss: 0.3535, Accuracy: 0.8435\n",
      "Test Loss: 0.3542, Accuracy: 0.8590\n",
      "Epoch [35/100], Loss: 0.3512, Accuracy: 0.7968\n",
      "Test Loss: 0.3546, Accuracy: 0.8238\n",
      "Epoch [36/100], Loss: 0.3497, Accuracy: 0.8509\n",
      "Test Loss: 0.3586, Accuracy: 0.8158\n",
      "Epoch [37/100], Loss: 0.3487, Accuracy: 0.7954\n",
      "Test Loss: 0.3526, Accuracy: 0.8418\n",
      "Epoch [38/100], Loss: 0.3502, Accuracy: 0.8087\n",
      "Test Loss: 0.3545, Accuracy: 0.8582\n",
      "Epoch [39/100], Loss: 0.3475, Accuracy: 0.8507\n",
      "Test Loss: 0.3495, Accuracy: 0.8665\n",
      "Epoch [40/100], Loss: 0.3413, Accuracy: 0.8607\n",
      "Test Loss: 0.3610, Accuracy: 0.8598\n",
      "Epoch [41/100], Loss: 0.3411, Accuracy: 0.8588\n",
      "Test Loss: 0.3653, Accuracy: 0.8292\n",
      "Epoch [42/100], Loss: 0.3466, Accuracy: 0.7538\n",
      "Test Loss: 0.3583, Accuracy: 0.8170\n",
      "Epoch [43/100], Loss: 0.3496, Accuracy: 0.8058\n",
      "Test Loss: 0.3521, Accuracy: 0.8420\n",
      "Epoch [44/100], Loss: 0.3420, Accuracy: 0.8210\n",
      "Test Loss: 0.3560, Accuracy: 0.8351\n",
      "Epoch [45/100], Loss: 0.3438, Accuracy: 0.8623\n",
      "Test Loss: 0.3527, Accuracy: 0.8623\n",
      "Epoch [46/100], Loss: 0.3405, Accuracy: 0.8481\n",
      "Test Loss: 0.3668, Accuracy: 0.8190\n",
      "Epoch [47/100], Loss: 0.3431, Accuracy: 0.8677\n",
      "Test Loss: 0.3594, Accuracy: 0.8306\n",
      "Epoch [48/100], Loss: 0.3463, Accuracy: 0.8468\n",
      "Test Loss: 0.3480, Accuracy: 0.8651\n",
      "Epoch [49/100], Loss: 0.3455, Accuracy: 0.7896\n",
      "Test Loss: 0.3737, Accuracy: 0.8126\n",
      "Epoch [50/100], Loss: 0.3431, Accuracy: 0.9290\n",
      "Test Loss: 0.3562, Accuracy: 0.8020\n",
      "Epoch [51/100], Loss: 0.3423, Accuracy: 0.8465\n",
      "Test Loss: 0.3484, Accuracy: 0.8579\n",
      "Epoch [52/100], Loss: 0.3405, Accuracy: 0.8293\n",
      "Test Loss: 0.3506, Accuracy: 0.8332\n",
      "Epoch [53/100], Loss: 0.3412, Accuracy: 0.8622\n",
      "Test Loss: 0.3514, Accuracy: 0.8381\n",
      "Epoch [54/100], Loss: 0.3395, Accuracy: 0.9138\n",
      "Test Loss: 0.3631, Accuracy: 0.8173\n",
      "Epoch [55/100], Loss: 0.3398, Accuracy: 0.8867\n",
      "Test Loss: 0.3512, Accuracy: 0.8421\n",
      "Epoch [56/100], Loss: 0.3402, Accuracy: 0.8630\n",
      "Test Loss: 0.3523, Accuracy: 0.8228\n",
      "Epoch [57/100], Loss: 0.3406, Accuracy: 0.8338\n",
      "Test Loss: 0.3515, Accuracy: 0.8315\n",
      "Epoch [58/100], Loss: 0.3405, Accuracy: 0.8123\n",
      "Test Loss: 0.3505, Accuracy: 0.8230\n",
      "Epoch [59/100], Loss: 0.3371, Accuracy: 0.8132\n",
      "Test Loss: 0.3488, Accuracy: 0.8278\n",
      "Epoch [60/100], Loss: 0.3356, Accuracy: 0.8665\n",
      "Test Loss: 0.3484, Accuracy: 0.8620\n",
      "Epoch [61/100], Loss: 0.3388, Accuracy: 0.7607\n",
      "Test Loss: 0.3466, Accuracy: 0.8155\n",
      "Epoch [62/100], Loss: 0.3334, Accuracy: 0.8584\n",
      "Test Loss: 0.3791, Accuracy: 0.7952\n",
      "Epoch [63/100], Loss: 0.3352, Accuracy: 0.8583\n",
      "Test Loss: 0.3614, Accuracy: 0.8063\n",
      "Epoch [64/100], Loss: 0.3375, Accuracy: 0.8059\n",
      "Test Loss: 0.3466, Accuracy: 0.8413\n",
      "Epoch [65/100], Loss: 0.3425, Accuracy: 0.8849\n",
      "Test Loss: 0.3518, Accuracy: 0.8708\n",
      "Epoch [66/100], Loss: 0.3381, Accuracy: 0.8362\n",
      "Test Loss: 0.3440, Accuracy: 0.8552\n",
      "Epoch [67/100], Loss: 0.3365, Accuracy: 0.8391\n",
      "Test Loss: 0.3462, Accuracy: 0.8423\n",
      "Epoch [68/100], Loss: 0.3347, Accuracy: 0.8488\n",
      "Test Loss: 0.3419, Accuracy: 0.8739\n",
      "Epoch [69/100], Loss: 0.3337, Accuracy: 0.8443\n",
      "Test Loss: 0.3564, Accuracy: 0.8506\n",
      "Epoch [70/100], Loss: 0.3369, Accuracy: 0.8955\n",
      "Test Loss: 0.3504, Accuracy: 0.8238\n",
      "Epoch [71/100], Loss: 0.3372, Accuracy: 0.8067\n",
      "Test Loss: 0.3403, Accuracy: 0.8877\n",
      "Epoch [72/100], Loss: 0.3297, Accuracy: 0.9014\n",
      "Test Loss: 0.3503, Accuracy: 0.8435\n",
      "Epoch [73/100], Loss: 0.3399, Accuracy: 0.8719\n",
      "Test Loss: 0.3646, Accuracy: 0.7933\n",
      "Epoch [74/100], Loss: 0.3331, Accuracy: 0.8780\n",
      "Test Loss: 0.3443, Accuracy: 0.8454\n",
      "Epoch [75/100], Loss: 0.3314, Accuracy: 0.8387\n",
      "Test Loss: 0.3448, Accuracy: 0.8392\n",
      "Epoch [76/100], Loss: 0.3346, Accuracy: 0.8351\n",
      "Test Loss: 0.3460, Accuracy: 0.8326\n",
      "Epoch [77/100], Loss: 0.3315, Accuracy: 0.8116\n",
      "Test Loss: 0.3469, Accuracy: 0.8186\n",
      "Epoch [78/100], Loss: 0.3290, Accuracy: 0.8564\n",
      "Test Loss: 0.3455, Accuracy: 0.8140\n",
      "Epoch [79/100], Loss: 0.3299, Accuracy: 0.8400\n",
      "Test Loss: 0.3649, Accuracy: 0.8396\n",
      "Epoch [80/100], Loss: 0.3370, Accuracy: 0.8583\n",
      "Test Loss: 0.3443, Accuracy: 0.8694\n",
      "Epoch [81/100], Loss: 0.3326, Accuracy: 0.8290\n",
      "Test Loss: 0.3439, Accuracy: 0.8352\n",
      "Epoch [82/100], Loss: 0.3278, Accuracy: 0.8742\n",
      "Test Loss: 0.3449, Accuracy: 0.8613\n",
      "Epoch [83/100], Loss: 0.3290, Accuracy: 0.8429\n",
      "Test Loss: 0.3638, Accuracy: 0.8546\n",
      "Epoch [84/100], Loss: 0.3318, Accuracy: 0.8759\n",
      "Test Loss: 0.3491, Accuracy: 0.8474\n",
      "Epoch [85/100], Loss: 0.3278, Accuracy: 0.8246\n",
      "Test Loss: 0.3451, Accuracy: 0.8478\n",
      "Epoch [86/100], Loss: 0.3350, Accuracy: 0.8606\n",
      "Test Loss: 0.3441, Accuracy: 0.8777\n",
      "Epoch [87/100], Loss: 0.3339, Accuracy: 0.8345\n",
      "Test Loss: 0.3442, Accuracy: 0.8825\n",
      "Epoch [88/100], Loss: 0.3273, Accuracy: 0.8371\n",
      "Test Loss: 0.3466, Accuracy: 0.8483\n",
      "Epoch [89/100], Loss: 0.3297, Accuracy: 0.8358\n",
      "Test Loss: 0.3619, Accuracy: 0.8275\n",
      "Epoch [90/100], Loss: 0.3286, Accuracy: 0.8603\n",
      "Test Loss: 0.3437, Accuracy: 0.8082\n",
      "Epoch [91/100], Loss: 0.3276, Accuracy: 0.8488\n",
      "Test Loss: 0.3515, Accuracy: 0.7972\n",
      "Epoch [92/100], Loss: 0.3287, Accuracy: 0.8393\n",
      "Test Loss: 0.3449, Accuracy: 0.8115\n",
      "Epoch [93/100], Loss: 0.3278, Accuracy: 0.8246\n",
      "Test Loss: 0.3428, Accuracy: 0.8436\n",
      "Epoch [94/100], Loss: 0.3260, Accuracy: 0.8228\n",
      "Test Loss: 0.3425, Accuracy: 0.8222\n",
      "Epoch [95/100], Loss: 0.3251, Accuracy: 0.8642\n",
      "Test Loss: 0.3415, Accuracy: 0.8560\n",
      "Epoch [96/100], Loss: 0.3273, Accuracy: 0.7641\n",
      "Test Loss: 0.3389, Accuracy: 0.8261\n",
      "Epoch [97/100], Loss: 0.3258, Accuracy: 0.8796\n",
      "Test Loss: 0.3427, Accuracy: 0.8592\n",
      "Epoch [98/100], Loss: 0.3231, Accuracy: 0.9165\n",
      "Test Loss: 0.3357, Accuracy: 0.8521\n",
      "Epoch [99/100], Loss: 0.3241, Accuracy: 0.8581\n",
      "Test Loss: 0.3477, Accuracy: 0.7904\n",
      "Epoch [100/100], Loss: 0.3243, Accuracy: 0.7816\n",
      "Test Loss: 0.3445, Accuracy: 0.8157\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "segmentationModel = CloudSegmentationModel().to(device)\n",
    "\n",
    "# train_loader = None # Train loader for our dataset\n",
    "# test_loader = None # Test loader for our dataset\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(segmentationModel.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "segmentationModel.train() \n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    running_loss = 0\n",
    "\n",
    "    segmentationModel.train()\n",
    "    for superpixel, label in train_loader:\n",
    "        superpixel = superpixel.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = segmentationModel(superpixel)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        ## Calculate accuracy\n",
    "        predicted = torch.round(output)\n",
    "        correct = (predicted == label).sum().item()\n",
    "        total = label.size(0) * label.size(1) * label.size(2)\n",
    "        accuracy = correct / total\n",
    "\n",
    "\n",
    "    # Print epoch statistics\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    segmentationModel.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for superpixel, label in test_loader:\n",
    "            superpixel = superpixel.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = segmentationModel(superpixel)\n",
    "            test_loss += criterion(output, label).item()\n",
    "\n",
    "            ## Calculate accuracy\n",
    "            predicted = torch.round(output)\n",
    "            correct = (predicted == label).sum().item()\n",
    "            total = label.size(0) * label.size(1) * label.size(2)\n",
    "            accuracy = correct / total\n",
    "\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    ## Print loss and accuracy\n",
    "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
